{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb104ead",
   "metadata": {},
   "source": [
    "## Before running this notebook\n",
    "## You have to be in the emk_analysis_mountainlab environment.\n",
    "\n",
    "## If you're not, close this notebook, shutdown jupyter and run this in terminal before restarting this notebook.\n",
    "\n",
    "`conda activate emk_analysis_mountainlab`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e577d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from emk_analysis import IO as emk_IO\n",
    "from emk_analysis import builder_experiment as bld_exp\n",
    "from emk_analysis import modules_DIO as md_dio\n",
    "from emk_analysis.routines_DIO import AnalyzeBehavior\n",
    "from emk_analysis import iterator as emk_iter\n",
    "from emk_analysis import extractor_dio\n",
    "from rec_to_binaries import binary_utils\n",
    "\n",
    "from mountainlab_pytools import mdaio\n",
    "\n",
    "from pprint import pprint\n",
    "from scipy import signal\n",
    "\n",
    "import os, time\n",
    "#os.environ['TZ'] = 'GMT'\n",
    "#time.tzset()\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import warnings\n",
    "from rec_to_binaries.read_binaries import readTrodesExtractedDataFile\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6fc525",
   "metadata": {},
   "source": [
    "## Experiment parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38641a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All of this should match your data file name.\n",
    "\n",
    "# eg. 20211203_[experiment_name]_[session id as 2 digit number]_[experiment phase]\n",
    "\n",
    "# Name of the folder where you have the data\n",
    "experiment_name = 'clc'\n",
    "\n",
    "#\n",
    "experiment_phase = 'stim'\n",
    "\n",
    "# data drive, where your data is located\n",
    "data_disk = 'nvme0'\n",
    "\n",
    "\n",
    "# Figure folder, where you want to save the output figures. Usually in your experiment folder for analysis.\n",
    "dir_fig = f'/media/{data_disk}/Analysis/{experiment_name}/Results/'\n",
    "\n",
    "# Location of track config file. \n",
    "# This is an excel spreadsheet that specifies the identities of the DIO for your experiment.\n",
    "fname_config_track = (f'/media/{data_disk}/Data/{experiment_name}/config/Maze_S_Config.xlsx')\n",
    "\n",
    "# Location of day records. \n",
    "# This is an excel spreadsheet that lists details for each session on your experiment day.\n",
    "dir_records = (f'/media/{data_disk}/Data/{experiment_name}/dayrecords/')\n",
    "\n",
    "# Which day or days you want to analyze. List of strings.\n",
    "choose_dates = [ '20211224',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301e74be",
   "metadata": {},
   "source": [
    "# Check the data path of the config file in the repo if data plotting does not work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecb29a",
   "metadata": {},
   "source": [
    "## Build day records from track confi file and experiment file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5840ff6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_days = []\n",
    "for curr_date in choose_dates:\n",
    "\n",
    "    fname_day_record = f'{dir_records}{curr_date}_{experiment_phase}_training_record.xlsx'\n",
    "    \n",
    "    dict_sessions_day = bld_exp.build_day_from_file(experiment_name, \n",
    "                                track_config_file=fname_config_track,\n",
    "                                day_record_file=fname_day_record)\n",
    "    data_days.append(dict_sessions_day)\n",
    "\n",
    "dict_sessions_all = bld_exp.build_all_sessions(data_days)\n",
    "pprint(dict_sessions_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e48d6dc",
   "metadata": {},
   "source": [
    "## Specifies the arrangement of your DIOs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e966b0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_sensor_pump_map = {1: {'pump': 'signal_pump'},\n",
    "                        2: {'pump': 'decision_pump'},\n",
    "                        7: {'sensor': 'trigger_sensor'},\n",
    "                        }\n",
    "\n",
    "# pump retrigger filter ms\n",
    "\n",
    "filter_retrigger = 0\n",
    "\n",
    "# get data for each animal\n",
    "\n",
    "# get data for each animal\n",
    "\n",
    "dict_list_animals = {'clc': ['clc', ]}\n",
    "\n",
    "dict_colors = {'clc': 'tab:blue',}\n",
    "\n",
    "\n",
    "dict_lines = {'1': '-',\n",
    "              '2': '--'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df71d45",
   "metadata": {},
   "source": [
    "## Initiate the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a542599",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select_animals = 'clc'\n",
    "\n",
    "# dict_plot_data_type = {'Percent Triggers Rewarded': {'ylim': [0, 100],\n",
    "#                                          'ylabel': '%'},\n",
    "#                   'Well Triggers': {'ylim': [0, 150],\n",
    "#                                    'ylabel': 'Count'}\n",
    "#                  }\n",
    "# choose_plot_data_type = 'Percent Triggers Rewarded'\n",
    "# choose_plot_data_type = 'Well Triggers'\n",
    "# list_animals = dict_list_animals.get(select_animals)\n",
    "# samp_freq = 30000\n",
    "\n",
    "# tick_day = mdates.DayLocator()\n",
    "# tick_day_fmt = mdates.DateFormatter('%b-%d')\n",
    "\n",
    "# reward_threshold = 25\n",
    "\n",
    "# date_range = [pd.to_datetime('20210112'), pd.to_datetime('20211231')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee61237",
   "metadata": {},
   "source": [
    "## Plot DIO raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c1b2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# # get data for each animal\n",
    "\n",
    "# # time plotting settings\n",
    "# tick_minutes = mdates.MinuteLocator(interval=5)\n",
    "# tick_minutes_fmt = mdates.DateFormatter('%H:%M')\n",
    "# tick_minor = mdates.SecondLocator(interval=10)\n",
    "\n",
    "\n",
    "# # list dio\n",
    "# list_dio = [1]\n",
    "\n",
    "# y_label = ['trigger', \n",
    "#               'laser on', \n",
    "#             ]\n",
    "\n",
    "# # plot each session\n",
    "# curr_group = select_animals\n",
    "# list_animals = dict_list_animals.get(curr_group)\n",
    "# for animal_id in list_animals:\n",
    "    \n",
    "    \n",
    "#     cls_behavior = emk_iter.ProcessBehavior(dict_sessions_all, \n",
    "#                                         experiment_name, trodes_version=2)\n",
    "\n",
    "#     cls_behavior.filter_animals(animal_id)\n",
    "\n",
    "#     print(animal_id)\n",
    "#     dict_rewards = cls_behavior.count_reward_delivered()\n",
    "#     if not dict_rewards:\n",
    "#         continue\n",
    "\n",
    "\n",
    "#     df_pump = cls_behavior.report_reward_delivered(remove_zeroth=False, \n",
    "#                                                output_raw=False, \n",
    "#                                                filter_retrigger=None)\n",
    "#     df_sensor = cls_behavior.report_triggers(remove_zeroth=False, \n",
    "#                                          output_raw=False, \n",
    "#                                          filter_retrigger=filter_retrigger)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22063c36",
   "metadata": {},
   "source": [
    "## Functions for filtering and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_freq_response(filter_name, order, lowcut, highcut, sampling_freq):\n",
    "    \n",
    "    if filter_name == 'elliptical': \n",
    "        sos = signal.ellip(order, 0.01, 120, [lowcut,highcut], btype = 'bp', output = 'sos', fs = sampling_freq)\n",
    "    if filter_name == 'butterworth':\n",
    "        sos = signal.butter(order, [lowcut,highcut], 'bp', fs = sampling_freq, output='sos')\n",
    "    if filter_name =='cheby1':\n",
    "        sos = signal.cheby1(order, 1, [lowcut, highcut], 'bp', fs=sampling_freq, output='sos')\n",
    "    if filter_name == 'cheby2':\n",
    "        sos = signal.cheby2(order, 15, [lowcut, highcut], 'bp', fs=sampling_freq, output='sos')\n",
    "\n",
    "   \n",
    "    \n",
    "    fig = plt.figure()\n",
    "    w, h = signal.sosfreqz(sos, worN=2000)\n",
    "    plt.plot((sampling_freq * 0.5 / np.pi) * w, abs(h), label=\"order = %d\" % order)\n",
    "    plt.xlabel('Frequency (Hz)')\n",
    "    plt.ylabel('Gain')\n",
    "    plt.grid(True)\n",
    "    plt.axvline(x=lowcut)\n",
    "    plt.axvline(x=highcut)\n",
    "    plt.xlim([lowcut*.7,highcut*1.3])\n",
    "    \n",
    "    plt.ylim([-0.1, 1.05])\n",
    "\n",
    "def bandpass_filter(filter_name, flattened_array, sampling_freq, order, lowcut, highcut):\n",
    "    \"\"\"\n",
    "    Return a dictionary of filtered lfp data\n",
    "\n",
    "    :param filter_name: name of the filter you want to use\n",
    "    :type filter_name: string\n",
    "    :param flattened_array: array of the raw lfp data\n",
    "    :type flattened_array: np array\n",
    "    :param sampling_freq: frequency lfp data was sampled at\n",
    "    :type sampling_freq: int\n",
    "    :param order: order of filter\n",
    "    :type order: int\n",
    "    :param lowcut: lower border of frequencies allowed to pass\n",
    "    :type lowcut: int\n",
    "    :param highcut: upper border of frequencies allowed to pass\n",
    "    :type highcut: int\n",
    "    \n",
    "\n",
    "    \n",
    "   \n",
    "    :return: filtered lfp data\n",
    "    :rtype: np array\n",
    "\n",
    "    \"\"\"\n",
    "    if filter_name == 'elliptical': \n",
    "        sos = signal.ellip(order, 0.01, 120, [lowcut,highcut], btype = 'bp', output = 'sos', fs = sampling_freq)\n",
    "    if filter_name == 'butterworth':\n",
    "        sos = signal.butter(order, [lowcut,highcut], 'bp', fs = sampling_freq, output='sos')\n",
    "    if filter_name =='cheby1':\n",
    "        sos = signal.cheby1(order, 1, [lowcut, highcut], 'bp', fs=sampling_freq, output='sos')\n",
    "    if filter_name == 'cheby2':\n",
    "        sos = signal.cheby2(order, 15, [lowcut, highcut], 'bp', fs=sampling_freq, output='sos')\n",
    "\n",
    "    y = signal.sosfiltfilt(sos, flattened_array)\n",
    "    \n",
    "    \n",
    "    return y\n",
    "\n",
    "def filter_bands(lfp_array, define_bands, sampling_freq, filter_name):\n",
    "    \"\"\"\n",
    "    Return a dictionary of filtered lfp data\n",
    "\n",
    "    :param lfp_array: array of the raw lfp data\n",
    "    :type lfp_array: np array\n",
    "    :param define_bands: dictionary where keys are the band names, values are lists that define the order, band lowcut, and band highcut\n",
    "    :type define_bands: keys are strings, vals are lists of integers\n",
    "    :param sampling_freq: sampling frequency for lfp recordings\n",
    "    :type sampling_freq: int\n",
    "    :param filter_name: name of the filter you want to use\n",
    "    :type filter_name: string\n",
    "\n",
    "    \n",
    "   \n",
    "    :return: keys are the names of the bands, vals are the lfp data for the filtered band\n",
    "    :rtype: dictionary, keys are strings, vals are np arrays\n",
    "\n",
    "    \"\"\"\n",
    "    flattened_array = lfp_array.flatten()\n",
    "    bands = {}\n",
    "    \n",
    "    for key, val in define_bands.items():\n",
    "            bands.update({key: bandpass_filter(filter_name, flattened_array, sampling_freq, \n",
    "                                               val[0], val[1], val[2])})\n",
    "    \n",
    "    \n",
    "    return bands\n",
    "\n",
    "def plot_lfp_overlays(bands_dict, band_name, epoch, row, sampling_freq, start, end):\n",
    "    \n",
    "    lfp_raw = bands_dict['raw'] #[epoch-1][row] \n",
    "    lfp_band = bands_dict[band_name] #[epoch-1][row]\n",
    "    xvals = np.arange(0, len(lfp_band))/sampling_freq\n",
    "    \n",
    "    start = max(0, start * sampling_freq)\n",
    "    if end != -1:\n",
    "        end = min(len(xvals), end * sampling_freq)\n",
    "\n",
    "#     fig = plt.figure()\n",
    "    fig = plt.figure(figsize=(10,5))\n",
    "    \n",
    "    plt.plot(xvals[start : end], lfp_raw[start : end], color = 'lightgray', alpha = .8)\n",
    "    plt.plot(xvals[start : end], lfp_band[start : end], color = 'red', linewidth = 1)\n",
    "    \n",
    "    plt.title('Entire signal with '+ band_name+' overlay')\n",
    "#     return fig\n",
    "\n",
    "# Set of frequency bands\n",
    "\n",
    "define_bands = {'spike': [10, 600, 6000], }\n",
    "\n",
    "#define_bands = {\n",
    "#                'ripple': [20, 100, 250],}\n",
    "\n",
    "\n",
    "def load_time(data_path):\n",
    "    return readTrodesExtractedDataFile(data_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_mda(data_path):\n",
    "    return readTrodesExtractedDataFile(data_path)\n",
    "\n",
    "\n",
    "def extract_mda(lfp_raw, fs=1500):\n",
    "    \n",
    "    mda_data = mda_raw.get('data')\n",
    "    mda_data = [i[0] for i in mda_data]\n",
    "    indstart = 0\n",
    "    indend = len(lfp_data)\n",
    "    mda_timestamp = np.arange(indstart, indend)/(fs)\n",
    "    \n",
    "    return mda_data, mda_timestamp\n",
    "\n",
    "def filter_linenoise(fs = 1500):\n",
    "    f0 = 60  # Frequency to be removed from signal (Hz)\n",
    "    Q = 30  # Quality factor\n",
    "    # Design notch filter\n",
    "    b, a = signal.iirnotch(f0, Q, fs)\n",
    "    return {'b': b, 'a': a}\n",
    "    \n",
    "\n",
    "def remove_mda_linenoise(mda_input, filter_params):\n",
    "\n",
    "    mda_output = signal.filtfilt(filter_params.get('b'), \n",
    "                                      filter_params.get('a'), \n",
    "                                      mda_input)\n",
    "    return mda_output\n",
    "\n",
    "\n",
    "def iterate_mda_load(tet_list, data_dir, fname_date, fname_exp, \n",
    "                     fname_task, fname_epoch, linenoise_filter_params={}, define_bands={}):\n",
    "    mda_out = {}\n",
    "    \n",
    "    fdir = Path(data_dir, fname_date, f'{fname_date}_{fname_exp}_{fname_epoch}_{fname_task}.mountainsort')\n",
    "    \n",
    "    # list files\n",
    "    \n",
    "    for tet in tet_list:\n",
    "                \n",
    "        fpath_data = list(Path(fdir).rglob(f'*nt{tet}*mda'))\n",
    "        fpath_time = list(Path(fdir).rglob(f'*time*mda'))\n",
    "        if fpath_data:\n",
    "            print(f'{tet} - data loaded')\n",
    "        else:\n",
    "            print(f'{tet} - data not found')\n",
    "            continue\n",
    "            \n",
    "        pprint(fpath_data)\n",
    "        mda_raw = mdaio.readmda(f'{fpath_data[0]}')\n",
    "        mda_time = mdaio.readmda(f'{fpath_time[0]}')\n",
    "        \n",
    "        bands_dicts = [filter_bands(y, define_bands, 30000, 'elliptical') for y in mda_raw]\n",
    "        \n",
    "       # pprint(bands_dicts)\n",
    "        \n",
    "        mda_spike = [v.get('spike') for v in bands_dicts]\n",
    "        #if linenoise_filter_params:\n",
    "        #    mda_data = remove_mda_linenoise(mda_data, linenoise_filter_params)\n",
    "        mda_out.update({tet: {'raw': mda_raw,\n",
    "                              'spike': mda_spike,\n",
    "                             'timestamp': mda_time}})\n",
    "    \n",
    "    return mda_out, fpath_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1814e7",
   "metadata": {},
   "source": [
    "## Specify data to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e35659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File name format \n",
    "# eg. [fname_date]_[fname_exp]_[fname_epoch]_[fname_task].rec\n",
    "# eg 20211222_clc_02_stim\n",
    "\n",
    "# Day\n",
    "fname_date = '20211224'\n",
    "\n",
    "fname_exp = 'clc'\n",
    "\n",
    "fname_task = 'stim'\n",
    "\n",
    "fname_epoch = '01' # needs to be a string eg. '04'\n",
    "\n",
    "\n",
    "# tetrodes to load, a list\n",
    "tlist = [14, 15, 16, 17, 18, 19, ]\n",
    "tlist = [15, ]\n",
    "\n",
    "# directory where your processed file is located\n",
    "f_datadir = f'/media/{data_disk}/Data/{fname_exp}/preprocessing'\n",
    "\n",
    "\n",
    "# initiate filter for 60Hz mains noise\n",
    "linefilter = filter_linenoise()\n",
    "\n",
    "# load data\n",
    "dict_data, fpath_data = iterate_mda_load(tlist, f_datadir, fname_date, fname_exp, fname_task, fname_epoch, \n",
    "                             linenoise_filter_params=linefilter, define_bands=define_bands)\n",
    "\n",
    "# load timestamps\n",
    "dir_time = f'{f_datadir}/{fname_date}/{fname_date}_{fname_exp}_{fname_epoch}_stim.time/'\n",
    "path_time = f'{dir_time}{fname_date}_{fname_exp}_{fname_epoch}_stim.continuoustime.dat'\n",
    "dict_time = load_time(path_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26398be",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dict_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5a20d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/nvme0/Data/clc/data/stim_03_unix.txt','r') as f:\n",
    "    contents = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e4a35b",
   "metadata": {},
   "source": [
    "## Transform time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd032954",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time to common scale\n",
    "time_unix_start = int(dict_time.get('system_time_at_creation')) #trodes unix time\n",
    "time_internal_start = int(dict_time.get('timestamp_at_creation'))*-1\n",
    "time_clockrate = int(dict_time.get('timestamp_at_creation'))\n",
    "\n",
    "time_data = np.array(list(itertools.chain(*dict_time.get('data'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b33668",
   "metadata": {},
   "outputs": [],
   "source": [
    "trodes_PC_dif = float(contents[0][0:13])\n",
    "trodes_PC_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_dif = float(contents[1][0:17])\n",
    "system_dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ca3e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "py_stim_time = []\n",
    "for i in range(2,len(contents)):\n",
    "    current_PC_time = int(contents[i][0:19])\n",
    "    current_trodes_time = (current_PC_time-trodes_PC_dif-time_unix_start*(10**6))*(10**(-9))\n",
    "    py_stim_time.append(current_trodes_time)\n",
    "\n",
    "print(py_stim_time) # about 2 seconds between each timestamp\n",
    "print(len(py_stim_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a40330a",
   "metadata": {},
   "source": [
    "## Plot DIO events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "# get data for each animal\n",
    "\n",
    "# time plotting settings\n",
    "tick_minutes = mdates.MinuteLocator(interval=1)\n",
    "tick_minutes_fmt = mdates.DateFormatter('%H:%M:%S.%f')\n",
    "tick_minor = mdates.SecondLocator(interval=1)\n",
    "\n",
    "# \n",
    "dict_dio_out = {}\n",
    "\n",
    "\n",
    "# list dio\n",
    "list_dio = [2, 1, 7,]\n",
    "\n",
    "y_label = ['Decision', \n",
    "           'Signal generator on', \n",
    "           'Finger trigger'\n",
    "            ]\n",
    "\n",
    "# plot each session\n",
    "curr_group = 'clc'\n",
    "list_animals = dict_list_animals.get(curr_group)\n",
    "for animal_id in list_animals:\n",
    "    \n",
    "    \n",
    "    cls_behavior = emk_iter.ProcessBehavior(dict_sessions_all, \n",
    "                                        experiment_name, trodes_version=2)\n",
    "\n",
    "    cls_behavior.filter_animals(animal_id)\n",
    "\n",
    "    print(animal_id)\n",
    "    dict_rewards = cls_behavior.count_reward_delivered()\n",
    "    if not dict_rewards:\n",
    "        continue\n",
    "\n",
    "\n",
    "    df_pump = cls_behavior.report_reward_delivered(remove_zeroth=False, \n",
    "                                               output_raw=False, \n",
    "                                               filter_retrigger=None)\n",
    "    df_sensor = cls_behavior.report_triggers(remove_zeroth=False, \n",
    "                                         output_raw=False, \n",
    "                                         filter_retrigger=filter_retrigger)\n",
    "\n",
    "    # get unique sessions\n",
    "    sessions_unique = np.sort(df_sensor['session'].unique())\n",
    "    print(sessions_unique)\n",
    "    \n",
    "\n",
    "    \n",
    "    n_subplots = len(sessions_unique)\n",
    "    \n",
    "    \n",
    "    fig = plt.figure(figsize=(8, n_subplots*2+2))\n",
    "    axs = fig.subplots(n_subplots, 1)\n",
    "    \n",
    "    if n_subplots == 1:\n",
    "        axs = [axs, ]\n",
    "        sessions_unique = [sessions_unique[0], ]\n",
    "    \n",
    "    for sn, (ax, session) in enumerate(zip(axs, sessions_unique)):\n",
    "\n",
    "       \n",
    "        # get session times\n",
    "        \n",
    "        curr_start = dict_sessions_all.get(session).get('start')\n",
    "        curr_end = dict_sessions_all.get(session).get('end')\n",
    "        \n",
    "        # get sensor and pump times\n",
    "        \n",
    "        df_sensor_curr = df_sensor[df_sensor['session']==session]\n",
    "        df_sensor_curr = df_sensor_curr[(df_sensor_curr['on_time_sys']>=curr_start) \n",
    "                                       & (df_sensor_curr['on_time_sys']<curr_end)]\n",
    "        \n",
    "        df_pump_curr = df_pump[df_pump['session']==session]\n",
    "        df_pump_curr = df_pump_curr[(df_pump_curr['on_time_sys']>=curr_start) \n",
    "                                       & (df_pump_curr['on_time_sys']<curr_end)]\n",
    "\n",
    "        \n",
    "        dict_dio_out.update({int(session.split('_')[1]): df_pump_curr})\n",
    "        \n",
    "        for i, d in enumerate(list_dio):\n",
    "            #print(d)\n",
    "            \n",
    "            yval = i+1\n",
    "            \n",
    "            curr_pump_name = dict_sensor_pump_map.get(d).get('pump')\n",
    "            df_plot_pump = df_pump_curr[df_pump_curr['dio']==curr_pump_name]\n",
    "            #print(curr_pump_name)\n",
    "            #display(df_plot_pump)\n",
    "            \n",
    "            curr_sensor_name = dict_sensor_pump_map.get(d).get('sensor')\n",
    "            df_plot_sensor = df_sensor_curr[df_sensor_curr['dio']==curr_sensor_name]\n",
    "\n",
    "            # plot well triggers\n",
    "            for ind, row in df_plot_sensor.iterrows():\n",
    "                ax.scatter(row['on_time_sys'], yval, s=25, c='k')\n",
    "\n",
    "            for ind, row in df_plot_pump.iterrows():\n",
    "                try:\n",
    "                    ax.plot([row['on_time_sys'], \n",
    "                              row['off_time_sys']], [yval, yval], c='r')\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "                \n",
    "            \n",
    "        \n",
    "        ax.set_yticks([1, 2, 3])\n",
    "        ax.set_yticklabels(y_label)\n",
    "\n",
    "        ax.xaxis.set_major_formatter(tick_minutes_fmt)\n",
    "        ax.xaxis.set_minor_locator(tick_minor)\n",
    "        \n",
    "        ax.tick_params(axis='x', labelrotation=45, length=10, width=2)\n",
    "        ax.tick_params(axis='x', which='minor', length=5, width=2)\n",
    "        ax.tick_params(axis='both', labelsize=8)\n",
    "        ax.set_xlabel('Time')\n",
    "\n",
    "        ax.set_title((f'{animal_id} {session}'))\n",
    "        ax.set_ylim([0, 4])\n",
    "\n",
    "        ax.grid(c=[.9, .9, .9])\n",
    "        ax.set_axisbelow(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    \n",
    "    #fig_name = (f\"{dir_fig}Phase{experiment_phase}_DIO_{animal_id}_per_session.pdf\")\n",
    "    #plt.savefig(fig_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bd430b",
   "metadata": {},
   "source": [
    "## Plot the signal and DIO events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d647686",
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_on_time = []\n",
    "signal_off_time = []\n",
    "hardware_on_time = []\n",
    "hardware_off_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9b3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "dict_data_save = {}\n",
    "\n",
    "down_sample = 10\n",
    "\n",
    "\n",
    "for n, t in enumerate(tlist):\n",
    "    x = time_data[::down_sample] - time_data[0]\n",
    "    \n",
    "    for i in [0,]:\n",
    "        y = dict_data.get(t).get('raw')[i][::down_sample]\n",
    "        plt.plot(x/30000, y/1000+i*0.1+n, lw=0.25, c='k', label='Signal')\n",
    "    \n",
    "    dict_data_save.update({t: {'timestamp': x,\n",
    "                          'data': y}})\n",
    "        \n",
    "yval = -.5\n",
    "\n",
    "curr_dio = dict_dio_out.get(int(fname_epoch))\n",
    "\n",
    "# Plot the DIO data\n",
    "for ind, row in curr_dio.iterrows():\n",
    "    \n",
    "    #time_data[] is in sample count, and each second has 30000 samples\n",
    "    if row['dio'] == 'decision_pump':\n",
    "        hardware_on_time.append((row['on_time'] - time_data[0])/30000)\n",
    "        hardware_off_time.append((row['off_time'] - time_data[0])/30000)\n",
    "        plt.plot([(row['on_time'] - time_data[0])/30000, \n",
    "                  (row['off_time'] - time_data[0])/30000], \n",
    "                 [yval+.15, yval+.15], c='r')\n",
    "    if row['dio'] == 'signal_pump':\n",
    "        signal_on_time.append((row['on_time'] - time_data[0])/30000)\n",
    "        signal_off_time.append((row['off_time'] - time_data[0])/30000)\n",
    "        plt.plot([(row['on_time'] - time_data[0])/30000, \n",
    "                  (row['off_time'] - time_data[0])/30000], \n",
    "                 [yval, yval], c='b')\n",
    "\n",
    "# Plot python command out timestamps\n",
    "for py_time in py_stim_time:\n",
    "    plt.plot([py_time, py_time+0.005],[-0.4,-0.4],c='y')\n",
    "        \n",
    "# legend placeholder\n",
    "plt.plot([0], [0], c='r', label='Stimulation hardware on')\n",
    "plt.plot([0], [0], c='b', label='Signal generator on')\n",
    "plt.plot([0],[0],c='y',label='Algorithm command out')\n",
    "plt.legend()\n",
    "plt.ylim([-.7, .8])\n",
    "plt.xlabel('Time (s)')\n",
    "plt.ylabel('Signal (mV)')\n",
    "plt.title('Signal and Stim events')\n",
    "                    \n",
    "        \n",
    "# save data as csv\n",
    "out_dio_fname = f'laser_on_times_{fname_exp}_{fname_date}_{fname_epoch}'\n",
    "\n",
    "curr_dio_out = curr_dio[['on_time', 'off_time']]\n",
    "curr_dio_out_fname = f'{dir_fig}{out_dio_fname}.xlsx'\n",
    "print(curr_dio_out_fname)\n",
    "curr_dio_out.to_excel(curr_dio_out_fname, index=False)\n",
    "\n",
    "for k, v in dict_data_save.items():\n",
    "    data_save_fname = f'tetrode_recording_{fname_exp}_{fname_date}_{fname_epoch}_tet{k}'\n",
    "    for kk, vv in v.items():\n",
    "        data_save_path = f'{dir_fig}{data_save_fname}_{kk}.csv'\n",
    "        \n",
    "        with open(data_save_path, 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(vv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6638b3f4",
   "metadata": {},
   "source": [
    "## Average before and after light on or off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275d98ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will find all the decision on events and get the indices for a window around the event\n",
    "event_type = 'on_time'\n",
    "#event_type = 'off_time'\n",
    "window = 1\n",
    "fs = 30000\n",
    "\n",
    "curr_dio = dict_dio_out.get(int(fname_epoch))\n",
    "list_win_ind = []\n",
    "for ind, row in curr_dio.iterrows():\n",
    "    \n",
    "    if row['dio'] != 'decision_pump':\n",
    "        continue\n",
    "    \n",
    "    # on/off\n",
    "    curr_event = row[event_type]\n",
    "    \n",
    "    # get indices for current event\n",
    "    curr_event_ind = np.argmax(time_data >= curr_event)\n",
    "    \n",
    "    #print(curr_event_ind)\n",
    "    \n",
    "    # get current window\n",
    "    curr_win = [curr_event_ind - int(window*fs), curr_event_ind + int(window*fs)]\n",
    "    \n",
    "    list_win_ind.append(curr_win)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "822eaa08",
   "metadata": {},
   "source": [
    "## Plot the raw signals around the events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba5384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "x = np.arange(-window, window, 1/fs)\n",
    "\n",
    "plt.plot([0, 0], [-1, 1], c='r', lw=0.5)\n",
    "\n",
    "for n, t in enumerate(tlist):\n",
    "    for i in [1, ]:\n",
    "        y = dict_data.get(t).get('raw')[i] \n",
    "        [plt.plot(x, y[v[0]:v[1]]/1000+i*0.1+n, lw=0.5, c='k', alpha=.2) for v in list_win_ind]\n",
    "        \n",
    "plt.xlabel('Time window around event (s)')\n",
    "plt.ylabel('Signal (mV)')\n",
    "plt.title('Signal around Decision')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2ae839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the timestamps to milliseconds\n",
    "signal_on_ms = []\n",
    "signal_off_ms = []\n",
    "hardware_on_ms = []\n",
    "hardware_off_ms = []\n",
    "for i in range(len(signal_on_time)):\n",
    "    signal_on_ms.append(signal_on_time[i]*(10**3))\n",
    "    signal_off_ms.append(signal_off_time[i]*(10**3))\n",
    "    \n",
    "for i in range(len(hardware_on_time)):\n",
    "    hardware_on_ms.append(hardware_on_time[i]*(10**3))\n",
    "    hardware_off_ms.append(hardware_off_time[i]*(10**3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce42810",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_lags = []\n",
    "off_lags = []\n",
    "for i in range(len(signal_on_ms)):\n",
    "    curr_signal_on = signal_on_ms[i]\n",
    "    curr_signal_off = signal_off_ms[i]\n",
    "    for j in range(len(hardware_on_ms)):\n",
    "        curr_hardware_on = hardware_on_ms[j]\n",
    "        curr_hardware_off = hardware_off_ms[j]\n",
    "        on_lags.append(round(curr_hardware_on-curr_signal_on))\n",
    "        off_lags.append(round(curr_hardware_off-curr_signal_off))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0fbb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('On lag:'+str(on_lags[:100]))\n",
    "print(\"\\n\")\n",
    "print('Off lag:'+str(off_lags[:100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25808a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lag range -100~101: not quite possible for lag to go beyondm 100ms \n",
    "on_xcorr_hist,on_bin_edges = np.histogram(on_lags,range(-100,101))\n",
    "plt.figure()\n",
    "plt.bar(on_bin_edges[:-1],on_xcorr_hist)\n",
    "plt.xlabel(\"Time Lag(ms)\")\n",
    "plt.ylabel(\"Cross Correlatioin\")\n",
    "plt.title(\"Stimulation on Time Lag (%d Events)\"%len(signal_on_ms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c0d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "off_xcorr_hist, off_bin_edges = np.histogram(off_lags, range(200,601))\n",
    "plt.figure()\n",
    "plt.bar(off_bin_edges[:-1],off_xcorr_hist)\n",
    "plt.xlabel(\"Time Lag(ms)\")\n",
    "plt.ylabel(\"Cross Correlatioin\")\n",
    "plt.title(\"Stimulation off Time Lag (%d Events)\"%len(signal_on_ms))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
